一: 音视频的基础知识讲解:
    1.视频分辨率介绍:
          标清：意思就是“标准清晰度”，是物理分辨率在720p(p代表逐行扫描)以下的视频格式。是物理分辨率在1280P*720P以下的一种视频格式，是指视频的垂直分辨率为720线逐行扫描。具体的说，是指分辨率在400线左右的VCD、DVD、电视节目等“标清”视频格式，即标准清晰度。
           标清的分辨率:640×480、720×576,800×600


          高清：而物理分辨率达到720p以上的格式.简称HD.“高清”的标准：指视频的垂直分辨率为720线逐行扫描，也就是说电视的屏幕必须能够同时、完整地显示720条横线。高清的720p的分辨率:1280×720,1280×1024、1280×768、1280×800等分辨率也都支持720p高清格式。
       

       视频帧: 表示一张画面,一个视频就是由许许多多帧组成的。
       帧率:即单位时间内帧的数量，单位为：帧/秒 或fps（frames per second),一秒内包含多少张图片，图片越多，画面越顺滑，过渡越自然。
           (24/25 fps：1秒 24/25 帧，一般的电影帧率)

		色彩空间:RGB 我们最熟悉的一种颜色模式;
                YUV  Y：亮度，就是灰度值 U：蓝色 V：红色.人眼对亮度Y敏感，对色度UC不敏感.所以可以压缩UV的分辨率，在不影响观感的前提下，减小视频的体积 
       码率:是指一个数据流中每秒钟能通过的信息量，单位bps（bit per second）

      为什么要编码? 音视频的数据量庞大，如果按照裸流数据存储的话，那将需要耗费非常大的存储空间，也不利于传送。
                  特别在视频中，由于画面是逐渐过渡的，因此整个视频中，包含了大量画面/像素的重复，这正好提供了非常大的压缩空间。
                    编码可以大大减小音视频数据的大小，让音视频更容易存储和传送。
        
        视频编码
		视频编码格式:H26x系列和MPEG系列的编码.现在主流的编码格式H264.
        H264视频编码格式简介:
        I帧：关键帧。 帧内编码帧。 
        P帧： 向前参考帧。 压缩时只参考前一个帧。  
        B帧：前后参考帧。压缩时即参考前一个帧,又参考后一个帧。(B帧的优点:对视频的压缩率更高,存储数据量更少;缺点:)
        H264采用的是YUV. 
        YUV存储方式分为两大类：planar 和 packed。 planar：先存储所有Y，紧接着存储所有U，最后是V； 
         由于人眼对色度UV不敏感,所以可以通过省略一些色度信息,来达到压缩视频的效果,让亮度Y共用一些色度信息UV,
		 所以 planar又区分了以下几种格式： YUV444、 YUV422、YUV420
          YUV 4:4:4采样,每一个Y对应一组UV分量 
          YUV 4:2:2采样，每两个Y共用一组UV分量。
          YUV 4:2:0采样，每四个Y共用一组UV分量。(最常用的)
        H264的压缩技术: 
          
 

       
 	   音频编码 
       音频编码格式:   
        无损音频编码格式: 例如PCM，WAV，ALS，ALAC，TAK，FLAC，APE，WavPack(WV)
        有损音频编码格式: 例如MP3，AAC，WMA，Ogg   





      AAC音频编码简介: AAC一种高压缩比的音频压缩算法。在MP4视频中的音频数据，大多数时候都是采用AAC压缩格式。        
        AAC格式主要分为两种：ADIF、ADTS。
     
       音视频容器介绍:
        mp4(是个视频容器)支持H264、H265等视频编码和AAC、MP3等音频编码。mp4是目前最流行的视频格式，在移动端，一般将视频封装为mp4格式。
       硬解码和软解码
       软解码：利用CPU的计算能力来解码，通常如果CPU的能力不是很强的时候，一则解码速度会比较慢，二则手机可能出现发热现象。但是，由于使用统一的算法，兼容性会很好。
       硬解码，指的是利用手机上专门的解码芯片来加速解码。通常硬解码的解码速度会快很多，但是由于硬解码由各个厂家实现，质量参差不齐，非常容易出现兼容性问题。

       Android平台的硬解码:MediaCodec 是Android原生硬解码,比较简单,是一个编解码接口。
                          FFmpeg(第三方的)也可以实现软解吗,比较复杂。
                          OpenGL是对视频的编辑器
        








        
        ijkplayer的一些问题优化记录: https://blog.csdn.net/hejjunlin/article/details/57075026
   

   









二:视频录制上传 

视频录制上传：录制音频视频–>剪辑–>编码–>上传服务器 别人播放.




 
三: 视频播放


 播放流程: 获取流–>解码–>播放



四:直播

    
  1.直播的基本流程:

  
   推流端: 采集(采集声音和图像原始数据),渲染, 前处理(对声音图像进行处理美颜祛斑,加logo，时间戳),编码， 推流(通过tmpt推流给给服务器)
   
   服务器:  转码(服务端转码可以给各个平台通用)   录制(服务器录制视频流 方便以后的点播回看)  截图(对视频流截图做直播的封面)    鉴黄
   
   播放端/客户端: 拉流( 从服务端拉)  解码  播放    

   互动系统： 客户端的互动  聊天 礼物 点赞



 各个环节的知识点的介绍:

   1.采集: 采集，它解决的是，数据从哪里来的问题，那么，数据究竟从哪里来的呢 ？
  ![](https://s1.51cto.com/images/blog/201712/03/b8b432d58b5adff80501e2c556c11b98.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

(1)音频采集: 采集pcm的元素数据,通过编码器压缩成 mp3 aac 格式 
                   采样率:8赫兹  把采集的模拟信号转为 数字,采样率越高记录的音频数据越大详细,音频质量越高
                   位宽：位数,一般使用8/16位   位宽越大 声音约好
                  声道数:   1 单声道  2 双声道 
                  音频帧:  20 毫秒(0.02s)  一个 音频帧
         所以一个 音频帧的数据大小是: 8000*16*2*0.02=5120hit/8= 640字节

 
  (2)图像采集: 
        分辨率:  长宽 
         采样频率: 就是把采样就是把模拟信号转化为 数字。 0101来表示的数字信号
                   采样频率越高 保存的图片越多 质量越大
             采样格式:  采集的视频都是yuv 格式
                   传输通道:摄像头
      

  (3)采集源： 摄像头采集:社交直播平台 手机摄像头 
         屏幕录制采集:  游戏 录制 自己的电脑屏幕
          文件推流:   把音视频时时传递给客户端  如 春晚
          
   (4) 各个端的采集数据:
             (4.1)采集图像/视频数据  
             系统的摄像头采集图像/视频数据接口是什么？Android：Camera.setPreviewCallback():获取原始yuv数据bit字节数组
             系统的摄像头采集的图像/视频参数怎么配置？ 比如：分辨率、帧率、预览方向、对焦、闪光灯 等
             系统的摄像头输出的图像/视频数据，是什么格式? 图片：JPEG，视频数据：NV21，NV12，I420 等
       

              (4.2)采集音频数据 
               系统的麦克风采集音频数据接口是什么?Android：AudioRecord
               系统的麦克风采集音频数据参数怎么配置 ?    比如：采样率，通道号，位宽 等       
                系统的麦克风输出的音频数据，是什么格式？  PCM  

            
  


  2. 渲染处理:
     图像、视频最终都是要绘制到视图（View层）上面，而音频最终都是要输出到扬声器
      系统提供了哪些 API 可以绘制一张图片或者一帧 YUV 图像数据的 ？ Android：ImageView，SurfaceView，TextureView，OpenGL 等
      系统提供了哪些 API 可以播放一个 mp3 或者 pcm 数据 ？Android：AudioTrack 等


          
           
   3.前处理：
      影视频数据如何加工的:
    
![](https://s1.51cto.com/images/blog/201712/03/ae6838d019a1247fa4949eaf16e9f732.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)
  

       
       (1)视频的前处理：
       美颜: 美白 磨皮 算法;  滤镜:美颜的一种  改变画面风格  GPUImage 开源库处理滤镜效果,基于GPU运算速度快;  水印:logo 时间戳
      （2）音频的前处理 : 
            混音: 声音是一种波,将各种音频叠加,如果叠加的越多 声音的振幅就会越大,导致破音,无法识别,导致采样值溢出。
                  解决办法使用混音算法(平均算法 对齐算法),对声音的振幅做平滑处理,避免振幅过高,避免溢出
           降噪:录制的音频有噪音(人为/自然的噪音 ),影响录音的效果; 
                解决办法使用算法: 傅里叶变换算法:将音频分解
           变声: 音色 音调     SoundTouch 开源库 处理变声,变调         
           特效:


  4.编码:重中之重 会影响直播的体验
       编码就是压缩视频的数据的大小存储  减少传输上传的时间
       编码的如何处理减少视频数据量(5M-->0.5M)的大小的: 
         去除空间的yong余(无损压缩)： 去除相邻像素之间的相关性
         去除时间的yong余(无损压缩)：去除视频的相邻图像间的相似内容(相邻的2个视频图像的变化不大,对相似的内容可以进行去除)
         去除编码的yong余(无损压缩)：
         去除视觉的yong余(有损压缩)：去除视觉对图像中不敏感的内容(色彩 亮度)

     
       常见的视频编码器:  H264   H265      
       H264的介绍:     
         I帧:单独的帧内编码帧   
         P帧:前向预测编码帧(依赖前一个帧进行解码自己)
         B帧:双向预测编码帧(依赖前后2个帧进行解码自己)
         GOP: 2个I帧之间的图像组    

     常见的音频编码器:AAC PCM  WAV  OGG
       
  

  分辨率: 1280*720 
  采集格式: YUV420SP
  fps :30帧/s 

  摄像头压缩前的1s的采集的1帧的数据量= 5M
  压缩
  压缩后: 使用H264编码后,大约0.5M

 



5.推流
 (1) 直播推流推流协议
    RTMP协议:时时消息传输协议
    优点: 支持CDN  协议简单 平台容易实现  https 安全 
    缺点:  基于TCP 传输成本高(TCP三次握手,网络环境差时,不断的重试,导致发送速度慢)  不支持浏览器推送   私有协议
    
    WebRTC协议:
     优点:支持浏览器推送, 基于UDP 传输速度快
     缺点:弱网环境下 会导致传输的数据的顺序出现错乱,因为UDP传输是无连接的 接收数据和发送数据的顺序不一致。
         CDN支持差

    UDP自定义推流私有协议:
       为了直播的流畅度 提升用户的体验。
       开发成本高 CDN不友好
    
 (2) 推流的优化
   （2.1） 保证音频的优先传输: 
       发送的数据量太多太大 暂停一下编码
               

      

     
   (2.2)调整码率 FPS(每秒采集的帧数)  分辨率 
       码率越高 清晰度越高 编码的数据越多  传输变慢   网络不好 就会导致 播放流畅度降低卡顿
       


  (2.3) 介绍传输的数据,提升视频播放的流畅度: 更换编码器 H264  -->H265 较少20%的数据传输 


 



 5.服务器之转码
  转码:将压缩的视频流转为另一个视频流
  后台转码的目的: 为了适应不同的网络带宽(不同的分辨率视频对带宽要求不同),不同的终端处理视频的能力不同  
                转码可以为直播平台提供很多的增值服务(为直播加字幕水印)
                 
 
 

6. 服务器的录制视频
     用于点播回放功能,播放之前录制的视频  

7.  服务器的截图  
    截图用于 封面

8.服务器的鉴黄
    使用深度学习图片识别技术,对直播流进行控制。




9. 客户端的拉流
       客户端的直播拉流协议:
               RTMP  
               HTTP-FLV
               HLS 
据中提取原始数据
   
10. 客户端的解码:
      从影视频数
   硬解码

   软解码

  



 11. 客户端的 播放 :   
    

12.直播交互--聊天
 

13.直播交互--礼物



五：直播的几个步骤:
    1.从给播放器传入播放地址url，到播放画面显示出来，一般有如下几个步骤：
    (1) 解析DNS：将播放地址中的域名解析为对应的服务器 ip 地址
    (2)连接服务器，完成 http/rtmp协议 握手过程
     (3)接收服务器发送的数据，解协议解封装，拿到音视频数据解码播放
     
    香港卫视的 RTMP 直播流：rtmp://live.hkstv.hk.lxdns.com/live/hks
    W3C School 的测试 mp4 流：http://www.w3school.com.cn/i/movie.mp4


 
  六 :直播疑难杂症排查

   1. 播放失败报错     
       原因: (1)  域名解析失败： 如果播放地址的域名无法解析，一般断网了或者域名无效，会导致播放失败，   
            (2)服务器连接失败
            (3)不支持的网络协议、编码格式、封装格式:如果播放器遇到不支持的协议或者格式，也会导致播放失败
                      
              网络协议比如 http/https/rtmp/rtsp 
              编码格式比如 h.264，mpeg4，aac，speex 
               封装格式比如 flv，mp4，avi，rmvb 
            (4)播放只有音频没有视频，或者只有视频没有音频


  2.播放卡顿

     原因: (1)网络带宽不足 导致播放卡顿
              - 主播端的网络不好，导致推流上行不稳定

              - 服务端的线路质量不好，导致分发不稳定

              - 观众端的网络不好，导致拉流下行不稳定

          (2)播放设备性能不足 导致播放卡顿
              越高清的码率，对解码的要求也越高，很多手机性能不足以支撑 720P 甚至 1080P 的视频解码，
               导致实际解码播放的帧率远小于视频码流的实际帧率，从而产生卡顿。
                
              - 尽可能选择使用硬解，充分利用 GPU 加速

              - 如果有多种码流，尽可能在低端机上选择非高清码流

             - 增大缓冲区，有助于缓解解码不稳定带来的卡顿



          (3)视频流时间戳问题 导致播放卡顿
              播放器一般是严格根据码流中的音视频的时间戳来做音画同步的，因此，如果码流中的音视频时间戳出现错误，肯定会影响到播放画面的渲染时机。
              播放器一般 master 主时钟是单调递增的，当后来的视频帧小于了当前的主时钟，播放器就会做丢帧处理，从而导致播放的视频帧率远低于实际码流中的视频帧率，从而产生卡顿现象。   



 3.画面和声音不同步



    (1)画面和声音同步的概念:
     音画同步是指播放器正在渲染的每一帧画面和正在播放的每一段声音都是严格对应起来的，不存在人耳和肉眼可以分辨出来的偏差。
     播放器播放音视频时，会判断一帧视频和一帧音频是否要在同一个时间戳渲染和播放。
     如果时间戳不一致 那么就会导致播放音视频不同步的问题。
      
    
    (2)  导致播放的音频时间戳 和视频的时间戳 不一致的原因:
          2.1 对视频进行算法处理(美颜、滤镜,编码)后,重新获取视频的时间戳 就与原来的音频的时间戳不一致了，就会导致 不同步。
          2.2缓冲区导致的不同步
          2.3网络传输导致的不同步
          2.4 时间戳出现回退或者紊乱
          2.5 播放端性能问题:
              低端机型软解 1080P 的高清码流，会存在解码不够及时的问题，导致部分视频解码完成后，已经远慢于当前的音频时钟，只能丢弃，从而导致画面更新不及时，与正在播放的音频无法匹配上，从而产生音画不同步的现象。
              
             解决方案：使用硬解，选择较低清的码流，增大播放缓冲，等等。




4.界面不清晰/马赛克严重
       马赛克主要是指画面中出现多处类似小方块的图像，导致画面的局部或者整体看不清楚的情况。
       导致界面马赛克的原因: 
        (1)  编码压缩得越厉害,编码质量过低，画质损失就越多,不清晰,马赛克就越严重。  
      
					       决定视频 编码 的质量 的 五个参数:画质级别、码率、帧率、GOP 大小、码控方式
					               画质级别：H.264 有四种画质级别，Baseline  ，Extended  ，Main  ，High  ，级别越高，压缩的效果越好，但算法复杂度更高，导致功耗也更高。
					               码率：决定了视频被压缩的程度，码率越低，丢失的信息也就越多，画质也就越差。但是，带来的好处是占用的网络带宽会比较小，容易在互联网上传输，不容易出现卡顿。
					               帧率：每秒播放多少帧画面。决定了视频的流畅性，帧率越高，视频越流畅。
					               GOP 大小：决定了视频的延时，GOP 越小，延时就越小，但 GOP 小带来的问题是关键帧数量多，数据量变大，因此，同等码率下压缩出来的视频质量就会越差。 


      
          
5.黑屏、花屏、闪屏问题
      5.1黑屏的问题:
      首先要排查是那导致的黑屏问题?  推流端的问题?还是播放器的问题?
     
      (1) 编码器对 视频原数据的编码失败
             由于编码器参数配置或者某些机型的硬编兼容性问题 ,导致 编码器编码失败,无输出,没有视频数据送入到推流模块
          
      (2)播放器遇到不支持的视频格式,导致解码失败。  
    
    
      5.2播放视频花屏/绿屏的问题？

      5.3  播放闪屏 
            闪屏问题就是播放的过程中，两种不同的画面来回切换。
            网络不好的时候，播放器会频繁缓冲，曾遇到过一种案例，就是某直播 App 应用，在缓冲的时候，使用了一张广告图片，在某种极端弱网情况下，由于频繁缓冲，导致真实的播放画面和广告图片来回快速切换，导致闪屏现象。




     
        
6.播放器seekto拖动不准的问题:
     播放过程中，拖动进度条后，实际播放的位置跟松开拖动时的位置相差很远。
   
     6.1解播放器拖动的基本原理：
     视频是由一系列图像帧组成的，每一个帧都有对应的时间戳。拖动，就是告诉播放一个时间戳，由它直接跳转到指定的这一帧开始播放。   
     拖动到的时间点 = （进度条的 progress / 进度条最大值 100 ）x 视频总时长
     

     6.2seekto拖动不准的原因:
        (1)前后2个关键帧间隔太大 
             因为播放器通常会寻找离 seekTo 视频帧最近的一个关键帧，从该关键帧开始解码播放。  
             所以,如果关键帧的间隔越大，那么这个误差也就越大. 建议不要把关键帧间隔设置得太大。




7.直播过程中手机发热严重，耗电快的问题:
     直播时CPU/GPU 占用率高.
     (1)直播数据量太大:适当减少视频的尺寸和帧率，是可以明显降低后续环节 CPU/GPU 的负荷的，从而显著降低功耗。
        直播主要由：视频采集 -> 视频处理（剪裁、美颜、滤镜） -> 编码 -> 推流 这些环节组成。
               视频的尺寸（例如：1280 x 720 的图像，明显要比 320 x 240 的图像处理起来费劲）
               视频的帧率（例如：每秒 30 帧，明显要比每秒 15 帧，处理起来费劲）
    
     
    (2)大量的格式转换 导致耗电:尽可能减少不同格式之间的数据转换
           ffmpeg 解码的视频往往是 YUV 格式，而渲染显示往往需要 RGB 格式, 二者需要转换格式 很耗电。
           尽可能减少不同格式之间的数据转换，或者尽可能利用 GPU 来处理一些复杂的格式转换，比如利用 OpenGL 直接渲染 YUV 格式的数据，而不是用 CPU 做一次 YUV -> RGB 的转换，就是一个不错的选择。








